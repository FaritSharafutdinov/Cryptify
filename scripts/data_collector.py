import pandas as pd
import pandas_ta as ta
import numpy as np
import ccxt
import time
from datetime import datetime, timedelta
import requests
import yfinance as yf
import os
from sqlalchemy import create_engine, text # –î–æ–±–∞–≤–ª–µ–Ω—ã –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î

# ==============================================================================
# üöÄ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==============================================================================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
EXCHANGE_ID = 'binance'
SYMBOL = 'BTC/USDT'
TIMEFRAME = '1h'
YEARS_TO_FETCH = 2
SP500_TICKER = 'ES=F'
SP500_INTERVAL = '1h'
OI_SYMBOL_BYBIT = 'BTCUSDT'
OI_CATEGORY_BYBIT = 'linear'
OI_INTERVAL_BYBIT = '1h'
BASE_URL_BYBIT = "https://api.bybit.com"
ENDPOINT_OI_BYBIT = "/v5/market/open-interest"

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• (DB) ---
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –æ–±—â–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞
try:
    # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ config.py
    import sys
    from pathlib import Path
    project_root = Path(__file__).parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    from config import (
        DB_USER, DB_PASSWORD, DB_HOST, DB_NAME, DB_PORT,
        DATABASE_URL, DB_TABLE_FEATURES
    )
    DB_TABLE = DB_TABLE_FEATURES
except ImportError:
    # Fallback –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    import os
    DB_USER = os.getenv("DB_USER", "criptify_user")
    DB_PASSWORD = os.getenv("DB_PASSWORD", "criptify_password")
    DB_HOST = os.getenv("DB_HOST", "localhost")
    DB_NAME = os.getenv("DB_NAME", "criptify_db")
    DB_PORT = os.getenv("DB_PORT", "5432")
    DB_TABLE = "btc_features_1h"
    DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ü–∞–π–ø–ª–∞–π–Ω–∞ ---
# –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –±–∞—Ä–æ–≤ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å, —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
# (–æ–∫–Ω–æ Z-score = 100) + –∑–∞–ø–∞—Å –Ω–∞ –ø–µ—Ä–µ—Å—á–µ—Ç.
BARS_TO_FETCH_FOR_UPDATE = 200

# –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è Feature Engineering (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
COL_MAPPING = {
    'Open': 'BTC_Open',
    'High': 'BTC_High',
    'Low': 'BTC_Low',
    'Close': 'BTC_Close',
    'Volume': 'BTC_Volume',
    'SP500_Close': 'SP500_Close'
}
# ==============================================================================

# ==============================================================================
# üóÑÔ∏è –§–£–ù–ö–¶–ò–ò –ë–ê–ó–´ –î–ê–ù–ù–´–• (–ù–û–í–´–ô –ë–õ–û–ö)
# ==============================================================================

def get_db_engine():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∏–∂–æ–∫ SQLAlchemy –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ DB."""
    # –¢–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–ø—ã—Ç–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    for _ in range(5):
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–≤–∏–∂–∫–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
            engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': 10})
            with engine.connect() as connection:
                print("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
            return engine
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
            time.sleep(5)
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫.")
    return None

def get_last_timestamp(engine):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π timestamp –∏–∑ —Ç–∞–±–ª–∏—Ü—ã —Ñ–∏—á–µ–π."""
    try:
        query = text(f"SELECT MAX(timestamp) FROM {DB_TABLE}")
        with engine.connect() as connection:
            last_ts = connection.execute(query).scalar()
        
        if last_ts:
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ datetime.datetime –≤ pandas.Timestamp
            return pd.to_datetime(last_ts)
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ timestamp –∏–∑ –ë–î: {e}. –¢–∞–±–ª–∏—Ü–∞ –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å.")
        return None

def save_features_to_db(df: pd.DataFrame, engine):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç Pandas DataFrame –≤ —Ç–∞–±–ª–∏—Ü—É —Ñ–∏—á–µ–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å—Ö–µ–º—ã."""
    if df.empty:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø–∏—Å–∏.")
        return

    print(f"–ó–∞–ø–∏—Å—å/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ {len(df)} —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü—É '{DB_TABLE}'...")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –∫–∞–∫ –∫–æ–ª–æ–Ω–∫—É (–≤–∞–∂–Ω–æ –¥–ª—è to_sql)
    df_to_save = df.copy()
    df_to_save.index.name = 'timestamp'
    df_to_save = df_to_save.reset_index()

    try:
        # –î–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'replace' –∏–ª–∏ UPSERT (–Ω–æ —ç—Ç–æ —Å–ª–æ–∂–Ω–µ–µ —Å to_sql)
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤ —ç—Ç–æ–º –ø—Ä–∏–º–µ—Ä–µ, –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 'append'
        # –∏ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ —Ç–æ, —á—Ç–æ –≤ df_features_new –Ω–µ—Ç —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        df_to_save.to_sql(
            name=DB_TABLE,
            con=engine,
            if_exists='append',
            index=False,
        )
        print(f"‚úÖ –ó–∞–ø–∏—Å—å {len(df_to_save)} —Å—Ç—Ä–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ DB: {e}")
        print(f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ '{DB_TABLE}' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫—É 'timestamp' –∏ –≤—Å–µ —Ñ–∏—á–∏.")

# ==============================================================================
# üõ†Ô∏è –§–£–ù–ö–¶–ò–ò –°–ë–û–†–ê –î–ê–ù–ù–´–• (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================
# ... (fetch_ohlcv_data, fetch_open_interest_data, fetch_sp500_data - –û–°–¢–ê–í–ò–¢–¨ –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
# –Ø –æ–ø—É—Å–∫–∞—é –∏—Ö –∑–¥–µ—Å—å –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, –Ω–æ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ.

def fetch_ohlcv_data(exchange_id, symbol, timeframe, start_date):
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ fetch_ohlcv_data
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({'enableRateLimit': True})
    except AttributeError:
        print(f"‚ùå –ë–∏—Ä–∂–∞ {exchange_id} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è ccxt.")
        return []

    since = int(start_date.timestamp() * 1000)
    all_ohlcv = []
    limit = 1000 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è ccxt

    print(f"\n--- 1. –°–±–æ—Ä OHLCV ---")
    print(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∏—Ä–∂–µ: {exchange_id.upper()}")
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π —Å–±–æ—Ä
    fetch_range = datetime.utcnow().replace(minute=0, second=0, microsecond=0) - start_date
    range_str = f"{fetch_range.days} –¥–Ω–µ–π" if fetch_range.days > 0 else f"{fetch_range.seconds // 3600} —á–∞—Å–æ–≤"
    print(f"–°–±–æ—Ä —á–∞—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {range_str} –Ω–∞—á–∏–Ω–∞—è —Å {start_date.strftime('%Y-%m-%d %H:%M:%S')}")

    # –õ–æ–≥–∏–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –æ—Å—Ç–∞–µ—Ç—Å—è –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å start_date
    while True:
        try:
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit)

            if not ohlcv:
                print("–î–∞–Ω–Ω—ã–µ OHLCV –±–æ–ª—å—à–µ –Ω–µ –ø–æ—Å—Ç—É–ø–∞—é—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            all_ohlcv.extend(ohlcv)

            since = ohlcv[-1][0] + 1

            next_date = datetime.fromtimestamp(since / 1000)
            print(f"–°–æ–±—Ä–∞–Ω–æ {len(all_ohlcv)} —Å–≤–µ—á–µ–π. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å {next_date.strftime('%Y-%m-%d %H:%M:%S')}...")
            
            time.sleep(exchange.rateLimit / 1000.0)  

        except ccxt.DDoSProtection as e:
            print(f"üö® –ó–∞—â–∏—Ç–∞ –æ—Ç DDoS: {e}. –û–∂–∏–¥–∞–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥...")
            time.sleep(10)
        except ccxt.ExchangeNotAvailable as e:
            print(f"‚ùå –ë–∏—Ä–∂–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break
        except Exception as e:
            print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ OHLCV: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break

    return all_ohlcv

def fetch_open_interest_data(symbol, category, interval, start_date):
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ fetch_open_interest_data
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    url = BASE_URL_BYBIT + ENDPOINT_OI_BYBIT
    start_ts = int(start_date.timestamp() * 1000)

    all_oi_data = []  
    limit = 200
    current_cursor = None
    previous_cursor = None

    print(f"\n--- 2. –°–±–æ—Ä Open Interest ---")
    fetch_range = datetime.utcnow().replace(minute=0, second=0, microsecond=0) - start_date
    range_str = f"{fetch_range.days} –¥–Ω–µ–π" if fetch_range.days > 0 else f"{fetch_range.seconds // 3600} —á–∞—Å–æ–≤"
    print(f"–°–±–æ—Ä —á–∞—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {range_str} –Ω–∞—á–∏–Ω–∞—è —Å {start_date.strftime('%Y-%m-%d %H:%M:%S')}")

    while True:
        params = {
            "category": category,
            "symbol": symbol,
            "intervalTime": interval,
            "limit": limit,
        }
        if current_cursor:
            params['cursor'] = current_cursor

        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            if data.get('retCode') != 0:
                 print(f"‚ùå –û—à–∏–±–∫–∞ API Bybit: {data.get('retMsg', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                 break

            result = data.get('result', {})
            oi_list = result.get('list', [])

            if not oi_list:
                print("–î–∞–Ω–Ω—ã–µ Open Interest –±–æ–ª—å—à–µ –Ω–µ –ø–æ—Å—Ç—É–ø–∞—é—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            previous_cursor = current_cursor
            current_cursor = result.get('nextPageCursor')

            if current_cursor == previous_cursor and all_oi_data:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: –ö—É—Ä—Å–æ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–±–æ—Ä–∞.")
                break

            current_oldest_ts = int(oi_list[-1]['timestamp'])
            
            # –õ–æ–≥–∏–∫–∞ Bybit API: –∫—É—Ä—Å–æ—Ä –¥–≤–∏–∂–µ—Ç—Å—è –Ω–∞–∑–∞–¥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏. 
            # –ú—ã —Å–æ–±–∏—Ä–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ–º start_ts.
            oi_list.reverse()
            all_oi_data.extend(oi_list)

            if current_oldest_ts < start_ts:
                 print("‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –∏–ª–∏ –ø—Ä–æ–π–¥–µ–Ω–∞ –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–±–æ—Ä–∞.")
                 break

            if not current_cursor:
                print("–ö—É—Ä—Å–æ—Ä –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—É—Å—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            time.sleep(0.5) 

        except Exception as e:
            print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ Bybit: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break

    if all_oi_data:
        all_oi_data.sort(key=lambda x: int(x['timestamp']))
        df_oi = pd.DataFrame(all_oi_data)
        df_oi['timestamp'] = pd.to_numeric(df_oi['timestamp'])
        df_oi = df_oi[df_oi['timestamp'] >= start_ts]
        df_oi.drop_duplicates(subset=['timestamp'], keep='first', inplace=True)
        return df_oi

    return pd.DataFrame()


def fetch_sp500_data(ticker, interval, start_date):
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ fetch_sp500_data
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    print(f"\n--- 3. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö S&P 500 ---")

    try:
        # yfinance –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ 'YYYY-MM-DD'
        start_date_str = start_date.strftime('%Y-%m-%d')
        df_sp500 = yf.download(
            ticker,
            start=start_date_str,
            interval=interval,
            progress=False,
        )

        if df_sp500.empty:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {ticker} –∏–ª–∏ DataFrame –ø—É—Å—Ç.")
            return pd.DataFrame()

        # –û—á–∏—Å—Ç–∫–∞ –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫
        if isinstance(df_sp500.columns, pd.MultiIndex):
            df_sp500.columns = [f'{col[0]}_{col[1]}' if col[0] else col[1] for col in df_sp500.columns]
        
        if 'Adj Close' in df_sp500.columns:
            df_sp500.drop(columns=['Adj Close'], inplace=True)
            
        df_sp500.index.name = 'timestamp'
        df_sp500 = df_sp500.tz_localize(None) 
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(df_sp500)} —Å–≤–µ—á–µ–π S&P 500.")
        return df_sp500

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ S&P 500: {e}")
        return pd.DataFrame()

# ==============================================================================
# üß© –õ–û–ì–ò–ö–ê –û–ë–™–ï–î–ò–ù–ï–ù–ò–Ø –î–ê–ù–ù–´–• (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================
def merge_all_data(ohlcv_data, df_oi, df_sp500, sp500_ticker):
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ merge_all_data
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ DataFrame.
    """
    if not ohlcv_data:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ OHLCV.")
        return None
    
    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ OHLCV –≤ DataFrame
    df_ohlcv = pd.DataFrame(ohlcv_data, columns=['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
    df_ohlcv['timestamp'] = pd.to_datetime(df_ohlcv['timestamp'], unit='ms')
    df_ohlcv.set_index('timestamp', inplace=True)
    df_ohlcv = df_ohlcv[~df_ohlcv.index.duplicated(keep='first')]
    final_df = df_ohlcv
    
    # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Open Interest
    if not df_oi.empty:
        df_oi['timestamp'] = pd.to_datetime(df_oi['timestamp'], unit='ms')
        df_oi.set_index('timestamp', inplace=True)
        final_df = final_df.join(df_oi[['openInterest']].rename(
            columns={'openInterest': 'Open_Interest'}), how='left')
    
    # 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å S&P 500
    if not df_sp500.empty:
        final_df = final_df.join(df_sp500, how='left')

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ S&P 500 ---
        # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ S&P 500 –∏ –∫–æ–ª–æ–Ω–∫–∏ BTC
        sp500_columns = [col for col in final_df.columns if sp500_ticker in str(col) or str(col) in ['Open', 'High', 'Low', 'Close', 'Volume']]

        # ffill –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–ª—è–º–∏.
        final_df[sp500_columns] = final_df[sp500_columns].ffill()
        final_df[sp500_columns] = final_df[sp500_columns].fillna(0)

        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫, –≥–¥–µ S&P 500 –±—ã–ª —Ä–∞–≤–µ–Ω 0 (–∞–∫—Ç—É–∞–ª—å–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –±—ç–∫—Ñ–∏–ª–ª–∞)
        is_sp500_zero = (final_df[['Close', 'High', 'Low', 'Open']].eq(0)).all(axis=1) # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ OHLCV
        if False in is_sp500_zero.values:
            first_valid_row_index = is_sp500_zero.idxmin()
            rows_before = final_df.index.get_loc(first_valid_row_index)
            rows_to_drop = final_df.iloc[:rows_before]
            final_df = final_df.drop(rows_to_drop.index, axis=0)

    # 4. –§–∏–Ω–∞–ª—å–Ω–æ–µ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –°—Ç–æ–ª–±—Ü–æ–≤
    btc_rename_map = {
        'Open': 'BTC_Open',
        'High': 'BTC_High',
        'Low': 'BTC_Low',
        'Close': 'BTC_Close',
        'Volume': 'BTC_Volume'
    }
    final_df.rename(columns=btc_rename_map, inplace=True)

    new_column_names = {}
    yfinance_prefix = "SP500_"

    for col in final_df.columns:
        col_str = str(col)
        
        if SP500_TICKER in col_str:
            if 'Close' in col_str:
                new_name = f"{yfinance_prefix}Close"
            elif 'Open' in col_str:
                new_name = f"{yfinance_prefix}Open"
            elif 'High' in col_str:
                new_name = f"{yfinance_prefix}High"
            elif 'Low' in col_str:
                new_name = f"{yfinance_prefix}Low"
            elif 'Volume' in col_str:
                new_name = f"{yfinance_prefix}Volume"
            else:
                new_name = col_str
            new_column_names[col] = new_name

    final_df.rename(columns=new_column_names, inplace=True)
    return final_df

# ==============================================================================
# üìä –§–£–ù–ö–¶–ò–ò FEATURE ENGINEERING (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================
def calculate_log_return(series, periods=1):
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ calculate_log_return
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    """
    –†–∞—Å—á–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞.
    """
    return np.log(series / series.shift(periods))

def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ create_advanced_features
    # ... (–û—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–µ —Ñ–∏—á–∏, –≤–∫–ª—é—á–∞—è SP500 log return,
    –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –±–µ–∑ look-ahead bias.
    """
    df_temp = df.copy()
    
    # 1. –ü–°–ï–í–î–û–ù–ò–ú–´ –î–õ–Ø –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–°–¢–ò (–¥–ª—è pandas_ta)
    for old_name, new_name in COL_MAPPING.items():
        if new_name in df_temp.columns and old_name not in df_temp.columns:
            df_temp[old_name] = df_temp[new_name]
            
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Open –¥–ª—è price_change, –µ—Å–ª–∏ –æ–Ω–æ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ
    if 'BTC_Open' in df_temp.columns and 'Open' not in df_temp.columns:
        df_temp['Open'] = df_temp['BTC_Open']

    ## 2. –û–°–ù–û–í–ù–´–ï –§–ò–ß–ò
    df_temp['log_return'] = calculate_log_return(df_temp['Close'])
    df_temp['SP500_log_return'] = calculate_log_return(df_temp['SP500_Close'])
    
    ## 3. –°–¢–ê–¶–ò–û–ù–ê–†–ù–´–ï –¶–ï–ù–û–í–´–ï –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø (BTC)
    prev_close = df_temp['Close'].shift(1)
    df_temp['price_range'] = (df_temp['High'] - df_temp['Low']) / prev_close
    df_temp['price_change'] = (df_temp['Close'] - df_temp['Open']) / df_temp['Open']
    df_temp['high_to_prev_close'] = (df_temp['High'] - prev_close) / prev_close
    df_temp['low_to_prev_close'] = (df_temp['Low'] - prev_close) / prev_close

    ## 4. –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ –ò –û–ë–™–ï–ú (–û–∫–Ω–∞ 5, 14, 21, 100)
    for window in [5, 14, 21]:
        df_temp[f'volatility_{window}'] = df_temp['log_return'].rolling(window=window).std()
        df_temp[f'volume_ma_{window}'] = df_temp['Volume'].rolling(window=window).mean()
    vol_mean_100 = df_temp['Volume'].rolling(100).mean()
    vol_std_100 = df_temp['Volume'].rolling(100).std()
    df_temp['volume_zscore'] = (df_temp['Volume'] - vol_mean_100) / vol_std_100


    ## 5. –ë–ï–ó–û–ü–ê–°–ù–´–ï –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ (–ù–∞ –æ—Å–Ω–æ–≤–µ prev_Close)
    df_temp['prev_Close'] = df_temp['Close'].shift(1)
    df_temp['prev_High'] = df_temp['High'].shift(1)
    df_temp['prev_Low'] = df_temp['Low'].shift(1)

    macd_data = df_temp.ta.macd(close='prev_Close', fast=12, slow=26, signal=9)
    if macd_data is not None:
        df_temp['MACD_safe'] = macd_data.iloc[:, 0]
        df_temp['MACDs_safe'] = macd_data.iloc[:, 1]
        df_temp['MACDh_safe'] = macd_data.iloc[:, 2]

    rsi_data = df_temp.ta.rsi(close='prev_Close', length=14)
    if rsi_data is not None:
        df_temp['RSI_safe'] = rsi_data

    atr_data = df_temp.ta.atr(high='prev_High', low='prev_Low', close='prev_Close', length=14)
    if atr_data is not None:
        df_temp['ATR_safe_norm'] = atr_data / df_temp['prev_Close']
    
    df_temp.drop(['prev_Close', 'prev_High', 'prev_Low'], axis=1, inplace=True, errors='ignore')


    ## 6. –í–†–ï–ú–ï–ù–ù–´–ï –§–ò–ß–ò (–¶–ò–ö–õ–ò–ß–ï–°–ö–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï)
    df_temp['hour_sin'] = np.sin(2 * np.pi * df_temp.index.hour / 24)
    df_temp['hour_cos'] = np.cos(2 * np.pi * df_temp.index.hour / 24)
    df_temp['day_sin'] = np.sin(2 * np.pi * df_temp.index.dayofweek / 7)
    df_temp['day_cos'] = np.cos(2 * np.pi * df_temp.index.dayofweek / 7)
    df_temp['month_sin'] = np.sin(2 * np.pi * df_temp.index.month / 12)
    df_temp['month_cos'] = np.cos(2 * np.pi * df_temp.index.month / 12)

    ## 7. –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê
    cols_to_drop = list(COL_MAPPING.keys()) + list(COL_MAPPING.values())
    cols_to_drop.extend(['Open', 'High', 'Low', 'Close', 'Volume','SP500_High', 'SP500_Low', 'SP500_Open', 'SP500_Volume'])
    
    final_cols_to_drop = set(c for c in cols_to_drop) - set(['Close']) # 'Close' –∑–¥–µ—Å—å –±—É–¥–µ—Ç BTC_Close –≤ –Ω–æ–≤–æ–º –Ω–∞–∑–≤–∞–Ω–∏–∏

    # –í–Ω–∏–º–∞–Ω–∏–µ: –ü–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è BTC_Close –æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ 'Close' –≤ df_temp, –µ—Å–ª–∏ –Ω–µ –±—ã–ª –≤ COL_MAPPING
    # –í –∏—Å—Ö–æ–¥–Ω–æ–º –∫–æ–¥–µ, COL_MAPPING –≤–∫–ª—é—á–∞–µ—Ç 'Close', –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç—Å—è –≤ 'BTC_Close'.
    # –Ø —É–¥–∞–ª—è—é BTC_Open/High/Low/Volume, –Ω–æ –æ—Å—Ç–∞–≤–ª—è—é Close (BTC_Close), –∫–∞–∫ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    final_df = df_temp.drop(columns=list(final_cols_to_drop), errors='ignore')
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN (–ø–æ—è–≤–ª—è—é—Ç—Å—è –∏–∑-–∑–∞ rolling windows –∏ shift)
    final_df.dropna(inplace=True) 

    return final_df

# ==============================================================================
# ‚öôÔ∏è –û–°–ù–û–í–ù–û–ô –ü–ê–ô–ü–õ–ê–ô–ù: –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´ (–ê–î–ê–ü–¢–ò–†–û–í–ê–ù)
# ==============================================================================

def run_batch_history(engine):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ YEARS_TO_FETCH –∏ —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –ë–î.
    """
    print("\n" + "="*70)
    print("ü§ñ –≠–¢–ê–ü: –ü–û–õ–ù–´–ô –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ô –°–ë–û–† –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï")
    print("="*70)
    
    end_date = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    start_date = end_date - timedelta(days=364 * YEARS_TO_FETCH)

    try:
        # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        ohlcv_data = fetch_ohlcv_data(EXCHANGE_ID, SYMBOL, TIMEFRAME, start_date)
        df_oi = fetch_open_interest_data(OI_SYMBOL_BYBIT, OI_CATEGORY_BYBIT, OI_INTERVAL_BYBIT, start_date)
        df_sp500 = fetch_sp500_data(SP500_TICKER, SP500_INTERVAL, start_date)

        # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞
        df_raw = merge_all_data(ohlcv_data, df_oi, df_sp500, SP500_TICKER)
        
        if df_raw is None or df_raw.empty:
            print("‚ùå Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –ø—É—Å—Ç.")
            return
            
        print(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –†–∞–∑–º–µ—Ä: {len(df_raw)}")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # --- 3. FEATURE ENGINEERING ---
    print("\n" + "="*70)
    print("üî¨ –≠–¢–ê–ü 2: –°–û–ó–î–ê–ù–ò–ï –ò–ù–ñ–ï–ù–ï–†–ò–ù–ì–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("="*70)
    
    try:
        df_features = create_advanced_features(df_raw)
        
        # --- 4. –§–ò–ù–ê–õ–¨–ù–´–ô –í–´–í–û–î –ò –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–î ---
        # –í —Ä–µ–∂–∏–º–µ batch history –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º 'replace' –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Ç–∞–±–ª–∏—Ü—ã
        df_features.index.name = 'timestamp'
        df_features_to_save = df_features.reset_index()
        
        print(f"üíæ –°–æ–∑–¥–∞–Ω–∏–µ/–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å —Ç–∞–±–ª–∏—Ü—ã '{DB_TABLE}' –≤ –ë–î...")
        df_features_to_save.to_sql(
            name=DB_TABLE,
            con=engine,
            if_exists='replace', # –í–ê–ñ–ù–û: 'replace' –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏
            index=False,
        )
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        with engine.connect() as connection:
            connection.execute(text(f"CREATE UNIQUE INDEX IF NOT EXISTS idx_timestamp ON {DB_TABLE} (timestamp)"))
            connection.commit()
            
        print(f"‚úÖ –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü—É: {DB_TABLE}. –†–∞–∑–º–µ—Ä: {len(df_features)}")
        
    except Exception as e:
          print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ Feature Engineering –∏–ª–∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î: {e}")

def run_incremental_update(engine):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –µ–∂–µ—á–∞—Å–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–≤–µ—á–µ–π,
    –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –≤ –ë–î.
    """
    print("\n" + "="*70)
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ü§ñ –≠–¢–ê–ü 1: –°–ë–û–† –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•")
    print("="*70)
    
    # 0. –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–ê–†–¢–û–í–û–ô –î–ê–¢–´
    
    end_date = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞: 205 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Å–∞
    start_date_fetch = end_date - timedelta(hours=BARS_TO_FETCH_FOR_UPDATE + 5)
    last_timestamp = None
    
    # –ü–ï–†–ï–•–û–î: –ß–¢–ï–ù–ò–ï –ü–û–°–õ–ï–î–ù–ï–ì–û TIMESTAMP –ò–ó –ë–î
    last_timestamp = get_last_timestamp(engine)
    
    if last_timestamp is not None:
        # –û—Ç—Å—Ç—É–ø–∞–µ–º –Ω–∞–∑–∞–¥ –Ω–∞ —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (200 —á–∞—Å–æ–≤)
        fetch_from_date = last_timestamp - timedelta(hours=BARS_TO_FETCH_FOR_UPDATE)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—É—é –¥–∞—Ç—É, —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –ø–µ—Ä–µ—Å—á–µ—Ç —Å—Ç–∞—Ä—ã—Ö —Ñ–∏—á–µ–π
        if fetch_from_date > start_date_fetch:
            start_date_fetch = fetch_from_date
            
        print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω–∞. –ü–æ—Å–ª–µ–¥–Ω–∏–π timestamp: {last_timestamp}. –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä —Å: {start_date_fetch.strftime('%Y-%m-%d %H:%M:%S')}")
            
    # 1. –°–ë–û–† –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï
    try:
        ohlcv_data = fetch_ohlcv_data(EXCHANGE_ID, SYMBOL, TIMEFRAME, start_date_fetch)
        df_oi = fetch_open_interest_data(OI_SYMBOL_BYBIT, OI_CATEGORY_BYBIT, OI_INTERVAL_BYBIT, start_date_fetch)
        df_sp500 = fetch_sp500_data(SP500_TICKER, SP500_INTERVAL, start_date_fetch)

        df_raw_new = merge_all_data(ohlcv_data, df_oi, df_sp500, SP500_TICKER)
        
        if df_raw_new is None or df_raw_new.empty:
            print("‚ùå Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –ø—É—Å—Ç.")
            return
            
        print(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ) –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –†–∞–∑–º–µ—Ä: {len(df_raw_new)}")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # 2. FEATURE ENGINEERING (–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 200+ –±–∞—Ä–æ–≤)
    print("\n" + "="*70)
    print("üî¨ –≠–¢–ê–ü 2: –°–û–ó–î–ê–ù–ò–ï –ò–ù–ñ–ï–ù–ï–†–ò–ù–ì–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("="*70)
    
    try:
        df_features_new = create_advanced_features(df_raw_new)
        
        if df_features_new.empty:
            print("‚ö†Ô∏è DataFrame —Ñ–∏—á–µ–π –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            return

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ Feature Engineering: {e}")
        return

    # 3. –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï
    print("\n" + "="*70)
    print("üíæ –≠–¢–ê–ü 3: –û–ë–ù–û–í–õ–ï–ù–ò–ï –ü–û–°–¢–û–Ø–ù–ù–û–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•")
    print("="*70)
    
    # ‚ö†Ô∏è –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ï—Å–ª–∏ last_timestamp –Ω–µ None, –º—ã –º–æ–∂–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É
    if last_timestamp is not None:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–æ–≤–µ–µ, —á–µ–º –≤ –±–∞–∑–µ
        new_features_to_append = df_features_new[df_features_new.index > last_timestamp]
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ–∫–Ω–µ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ (200 –±–∞—Ä–æ–≤) –∏ —É–∂–µ –µ—Å—Ç—å –≤ –ë–î,
        # –∏—Ö –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å. –ù–æ –≤ –¥–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å `if_exists='append'` —ç—Ç–æ —Å–ª–æ–∂–Ω–æ.
        # –ú—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∑–∞–ø—É—Å–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∞—Å—Ç–æ, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤,
        # –∏–¥—É—â–∏—Ö —Å—Ä–∞–∑—É –∑–∞ `last_timestamp`. 
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∏—Å–∫, —Ç–æ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å UPSERT (ON CONFLICT DO UPDATE).
        
        if new_features_to_append.empty:
            print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç—É–∞–ª—å–Ω–∞. –ù–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–µ—Ç.")
            return

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫)
        save_features_to_db(new_features_to_append, engine)
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –≤: {DB_TABLE}. –î–æ–±–∞–≤–ª–µ–Ω–æ: {len(new_features_to_append)}")
    else:
        # –ï—Å–ª–∏ –±–∞–∑–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞)
        print("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è (Batch History).")
        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –≤ —Ä–µ–∂–∏–º –ø–æ–ª–Ω–æ–π –∑–∞–ø–∏—Å–∏ (—á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É)
        run_batch_history(engine)
        
    print("="*70)


if __name__ == '__main__':
    engine = get_db_engine()
    if engine is None:
        exit(1) # –í—ã—Ö–æ–¥, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î

    # –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö: –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –±–∞–∑—É (–Ω–∞ 2 –≥–æ–¥–∞).
    # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —ç—Ç—É —Å—Ç—Ä–æ–∫—É –Ω—É–∂–Ω–æ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!
    run_batch_history(engine) 
    
    # –ï–ñ–ï–ß–ê–°–ù–û–ï –û–ë–ù–û–í–õ–ï–ù–ò–ï: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ cron/–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ.
    run_incremental_update(engine)